## To do
- 데일리루틴
- 데이콘 1등과 내코드 비교 공부하기

## Dacon Following Winner's solution
```python
#!/usr/bin/env python
# coding: utf-8

# In[1]:


get_ipython().system('nvidia-smi')


# In[85]:


DATA_PATH = './data/'
SRC_COLUMNS = ['650_src', '660_src', '670_src', '680_src', '690_src',
       '700_src', '710_src', '720_src', '730_src', '740_src', '750_src',
       '760_src', '770_src', '780_src', '790_src', '800_src', '810_src',
       '820_src', '830_src', '840_src', '850_src', '860_src', '870_src',
       '880_src', '890_src', '900_src', '910_src', '920_src', '930_src',
       '940_src', '950_src', '960_src', '970_src', '980_src', '990_src']
DST_COLUMNS = ['650_dst', '660_dst', '670_dst', '680_dst', '690_dst', '700_dst',
       '710_dst', '720_dst', '730_dst', '740_dst', '750_dst', '760_dst',
       '770_dst', '780_dst', '790_dst', '800_dst', '810_dst', '820_dst',
       '830_dst', '840_dst', '850_dst', '860_dst', '870_dst', '880_dst',
       '890_dst', '900_dst', '910_dst', '920_dst', '930_dst', '940_dst',
       '950_dst', '960_dst', '970_dst', '980_dst', '990_dst']
TGT_COLUMNS = ['hhb', 'hbo2', 'ca', 'na']


# # Feature generation

# In[86]:


import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler


# In[87]:


train = pd.read_csv(DATA_PATH+ 'train.csv')
test = pd.read_csv(DATA_PATH+ 'test.csv')


# In[88]:


ZERO_COLUMNS = []
for i,_ in enumerate(DST_COLUMNS):
    for df in [train, test]:
        df['zero'+DST_COLUMNS[i][:3]] = df[DST_COLUMNS[i]].isnull().astype(int)
    ZERO_COLUMNS.append('zero'+DST_COLUMNS[i][:3])


# In[89]:


ZERO_COLUMNS


# In[90]:


train.filter(regex='^zero')


# In[91]:


ZERO_SRC_COLUMNS = []
for i,_ in enumerate(DST_COLUMNS):
    for df in [train, test]:
        df['zerosrc'+SRC_COLUMNS[i][:3]] = (df[SRC_COLUMNS[i]]==0).astype(float)
    ZERO_SRC_COLUMNS.append('zerosrc'+DST_COLUMNS[i][:3])


# In[92]:


ZERO_SRC_COLUMNS


# In[93]:


train.filter(regex='zerosrc')


# In[94]:


LEN_COLUMNS = []
for i,_ in enumerate(SRC_COLUMNS):
    for df in [train, test]:
        df['len'+SRC_COLUMNS[i][:3]] = float(SRC_COLUMNS[i][:3])
    LEN_COLUMNS.append('len'+SRC_COLUMNS[i][:3])


# In[95]:


train.filter(regex='^len')


# In[96]:


def interpolate_arr(xs):
    x = pd.DataFrame({'x':xs})
    return x['x'].interpolate().values


# In[97]:


train[DST_COLUMNS]


# In[98]:


for df in [train, test]:
    df[DST_COLUMNS] = df.apply(lambda x : interpolate_arr(x[DST_COLUMNS].values),
                               axis=1,
                               result_type='expand')


# In[99]:


train[DST_COLUMNS]


# In[100]:


train[DST_COLUMNS].describe()


# In[101]:


for i,_ in enumerate(DST_COLUMNS):
    for df in [train, test]:
        df[SRC_COLUMNS[i]] = np.log(df[SRC_COLUMNS[i]] + 1e-23)
        df[DST_COLUMNS[i]] = np.log(df[DST_COLUMNS[i]] + 1e-23)


# In[102]:


target_scaler = MinMaxScaler(feature_range=(-1,1)).fit(train[TGT_COLUMNS])
src_scaler = StandardScaler().fit(train[SRC_COLUMNS].values.ravel().reshape(-1,1))
dst_scaler = StandardScaler().fit(train[DST_COLUMNS].values.ravel().reshape(-1,1))
len_scaler = StandardScaler().fit(train[LEN_COLUMNS].values.ravel().reshape(-1,1))


# In[113]:


for df in [train, test]:
    for f in SRC_COLUMNS:
        df[f] = src_scaler.transform(df[[f]])
    for f in DST_COLUMNS:
        df[f] = dst_scaler.transform(df[[f]])
    for f in LEN_COLUMNS:
        df[f] = len_scaler.transform(df[[f]])
    if TGT_COLUMNS[0] in df.columns:
        df[TGT_COLUMNS] = target_scaler.transform(df[TGT_COLUMNS])
    
    for i in [10,15,20,25]:
        df['rho_'+str(i)] = 0
        df.loc[df['rho']==i, 'rho_'+str(i)] = 1
    df['rho'] /= df['rho'].max()
    df.fillna(0, inplace=True)


# In[115]:


train.filter(regex='^rho_')


# In[114]:


train.describe()


# # Batch Generator

# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[76]:


train[SRC_COLUMNS].describe()


# In[80]:


test_df = pd.DataFrame(StandardScaler().fit_transform(train[SRC_COLUMNS]), columns=SRC_COLUMNS)


# In[82]:


# 원래 하던대로 데이터프레임 전체에 스케일러를 적용한 경우
test_df.describe()


# In[83]:


target_scaler = MinMaxScaler(feature_range=(-1,1)).fit(train[TGT_COLUMNS])
src_scaler = StandardScaler().fit(train[SRC_COLUMNS].values.ravel().reshape(-1,1))
for df in [train,test]:
    for f in SRC_COLUMNS:
        df[f] = src_scaler.transform(df[[f]])


# In[84]:


# ravel하고 reshape해서 fit한 scaler로 컬럼마다 transform한 경우
train[SRC_COLUMNS].describe()


# In[ ]:





```