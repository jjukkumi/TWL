# daily todo

- RSS (https://v2.velog.io/rss/<velog이름>)
- spark
- adsp

# 스파크 스트리밍

<!-- ANCHOR 스파크스트리밍 정의 -->
```
주어진 데이터를 읽고 처리하는 것 뿐만 아니라 시간의 흐름에 따라 꾸준히 변화하는
데이터를다루기 위한 것.

대용량 데이터를 다루는 경우에는 데이터베이스를 활용한 처리가 불가능한 경우가 있는데,

이런 성격의 데이터를 다루기 위한 스파크의 서브 모듈로서 실시간으로 변화하는
데이터를(배치 처리보다) 짧은 주기에 맞춰 안정적으로 처리하는 데 필요한 기능 제공
```

## 스트리밍컨텍스트

<!-- ANCHOR streamingcontext -->
```python

스트리밍 모듈을 사용하기 위해서는 스트리밍컨텍스트(StreamingContext)인스턴스를 생성
어떤 주기로 배치 처리를 수행할지에 대한 정보(bathDuration)를 함께 제공

from pyspark import SparkContext, SparkConf, storagelevel
from pyspark.streaming.context import StreamingContext

conf = SparkConf()
conf.set("spark.drvier.host",'127.0.0.1')
sc = SparkContext(master="local",appName="StreamingSample",conf=conf)
ssc = StreamingContext(sc,3)

```

- 특징

1. 명시적인 시작(start),종료(stop),대기(awaitTermination) 메서드를 가지고 있다.

> 스파크컨텍스트와 스파크세션과는 달리 명시적으로 메서드를 호출해서 시작,종료를 시켜줘야한다.

2. 단 한번 시작되고 종료합니다. 즉 한번 종료한 스트리밍컨텍스트를 다시 재시작할 수 없습니다.

3. 한번 시작되고 나면 더 이상 새로운 연산을 정의하거나 추가할 수 없습니다.

4. JVM당 하나의 스트리밍 컨텍스트만 동시에 활성화 가능 

5. stop() 메서드를 호출하면 연관된 SparkContext도 함께 중지.

> 스트리밍컨텍스트만 종료하고 싶을 경우 stop() 메서드의 stopSparkContext 매개변수 값을 false로 지정

6. 한번에 하나의 스트리밍컨텍스트만 동작한다는 가정하에 하나의 스파크컨텍스트로부터 여러 개의 스트리밍 컨텍스트를 생성
